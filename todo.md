- so there was something in the docs about keywrds like "snowboy" or something. I should try to use that to update the code sot aht ehtere's a thread running thei bnckgrund that is just listening for the word `stop`. If the event is truggered during and `active_listening` period, ignore. Otherwise, immediateialey kill verbalitation and visualization
- update to write each session to disk as response/reply pair in a local directory called /sessions/<autogenerated_api_name>_session.json. This json contains an array of `query` types. A `query` consists of the request text, response text, recordings, times, etc.
- live rendering of dictation
- audio input for persona
- audio prompt on startup unless skip flag provided
- persistent sessions
- deal with pylint issues. There's lots. 
- right now the order is 1) send to AI 2) get response 3) play input and reponse? if so - fix that
- instead of hard coded exit message, , first pass the message to ai interface, then play response, then exit.
- add an input option of a string
- add an output option of a string
- add option to suppress turn indicators
- fix spot of first turn indicator
- implement some sort of notion of Entities (these would be all of the abstracted steps like Verbalizer and Logger and whatnot) and a configuration file. The man page would spit out 
- find out if there is a git hook that will automatically suggest updates to the README and/or unit tests upon attempt to merge
- need to consider play testers who don't want to spend a dime to play. Need to have an input flag called --demo-mode that uses the best version of everything that doesn't require creds/$