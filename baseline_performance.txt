============================================================
GANGLIA Performance Test Suite
============================================================
This script measures conversation pipeline latency

Initializing components...
Initializing GoogleTTS...
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1760678707.870662 2714829 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.
✓ Components initialized successfully

============================================================
Testing LLM Latency
============================================================

Query 1/5: What is 2+2?...
Sending query to AI server...
AI response received in 1.2 seconds.
⏱️  LLM Query 1: 1.20s
Response length: 15 chars

Query 2/5: Tell me a short joke....
Sending query to AI server...
AI response received in 1.2 seconds.
⏱️  LLM Query 2: 1.16s
Response length: 68 chars

Query 3/5: Explain what Halloween is in one sentence....
Sending query to AI server...
AI response received in 0.7 seconds.
⏱️  LLM Query 3: 0.71s
Response length: 167 chars

Query 4/5: What's the weather like today?...
Sending query to AI server...
AI response received in 1.6 seconds.
⏱️  LLM Query 4: 1.61s
Response length: 168 chars

Query 5/5: Give me a brief greeting....
Sending query to AI server...
AI response received in 1.2 seconds.
⏱️  LLM Query 5: 1.16s
Response length: 44 chars

============================================================
Testing TTS Latency
============================================================

Text 1/5: Hello there!...
Attempt 1/5 calling <lambda>...
Converting text to speech...
⏱️  TTS Generation 1: 0.31s
Generated: /tmp/GANGLIA/tts/chatgpt_response_Hello_there__20251017-002514.mp3

Text 2/5: The quick brown fox jumps over the lazy dog....
Attempt 1/5 calling <lambda>...
Converting text to speech...
⏱️  TTS Generation 2: 0.09s
Generated: /tmp/GANGLIA/tts/chatgpt_response_The_quick_brown_20251017-002514.mp3

Text 3/5: Happy Halloween! I hope you're having a spooky and...
Attempt 1/5 calling <lambda>...
Converting text to speech...
⏱️  TTS Generation 3: 0.10s
Generated: /tmp/GANGLIA/tts/chatgpt_response_Happy_Halloween__I_20251017-002514.mp3

Text 4/5: Testing text-to-speech generation performance with...
Attempt 1/5 calling <lambda>...
Converting text to speech...
⏱️  TTS Generation 4: 0.07s
Generated: /tmp/GANGLIA/tts/chatgpt_response_Testing_text-to-speech_generation_20251017-002514.mp3

Text 5/5: Short test....
Attempt 1/5 calling <lambda>...
Converting text to speech...
⏱️  TTS Generation 5: 0.08s
Generated: /tmp/GANGLIA/tts/chatgpt_response_Short_test__20251017-002514.mp3

============================================================
Testing End-to-End Latency (LLM + TTS)
============================================================

Query 1/3: What is 2+2?...
Sending query to AI server...
AI response received in 0.8 seconds.
Attempt 1/5 calling <lambda>...
Converting text to speech...
⏱️  End-to-End 1: 0.91s
Response: 15 chars → Audio: /tmp/GANGLIA/tts/chatgpt_response_2___2_20251017-002515.mp3

Query 2/3: Tell me a short joke....
Sending query to AI server...
AI response received in 1.5 seconds.
Attempt 1/5 calling <lambda>...
Converting text to speech...
⏱️  End-to-End 2: 1.77s
Response: 78 chars → Audio: /tmp/GANGLIA/tts/chatgpt_response_Why_did_the_20251017-002517.mp3

Query 3/3: Explain what Halloween is in one sentence....
Sending query to AI server...
AI response received in 1.5 seconds.
Attempt 1/5 calling <lambda>...
Converting text to speech...
⏱️  End-to-End 3: 2.06s
Response: 176 chars → Audio: /tmp/GANGLIA/tts/chatgpt_response_Halloween_is_a_20251017-002519.mp3


============================================================
PERFORMANCE SUMMARY
============================================================

End-to-End 1:
  Count:   1
  Mean:    0.91s
  Median:  0.91s
  P95:     0.91s
  P99:     0.91s
  Min:     0.91s
  Max:     0.91s

End-to-End 2:
  Count:   1
  Mean:    1.77s
  Median:  1.77s
  P95:     1.77s
  P99:     1.77s
  Min:     1.77s
  Max:     1.77s

End-to-End 3:
  Count:   1
  Mean:    2.06s
  Median:  2.06s
  P95:     2.06s
  P99:     2.06s
  Min:     2.06s
  Max:     2.06s

LLM Query 1:
  Count:   1
  Mean:    1.20s
  Median:  1.20s
  P95:     1.20s
  P99:     1.20s
  Min:     1.20s
  Max:     1.20s

LLM Query 2:
  Count:   1
  Mean:    1.16s
  Median:  1.16s
  P95:     1.16s
  P99:     1.16s
  Min:     1.16s
  Max:     1.16s

LLM Query 3:
  Count:   1
  Mean:    0.71s
  Median:  0.71s
  P95:     0.71s
  P99:     0.71s
  Min:     0.71s
  Max:     0.71s

LLM Query 4:
  Count:   1
  Mean:    1.61s
  Median:  1.61s
  P95:     1.61s
  P99:     1.61s
  Min:     1.61s
  Max:     1.61s

LLM Query 5:
  Count:   1
  Mean:    1.16s
  Median:  1.16s
  P95:     1.16s
  P99:     1.16s
  Min:     1.16s
  Max:     1.16s

TTS Generation 1:
  Count:   1
  Mean:    0.31s
  Median:  0.31s
  P95:     0.31s
  P99:     0.31s
  Min:     0.31s
  Max:     0.31s

TTS Generation 2:
  Count:   1
  Mean:    0.09s
  Median:  0.09s
  P95:     0.09s
  P99:     0.09s
  Min:     0.09s
  Max:     0.09s

TTS Generation 3:
  Count:   1
  Mean:    0.10s
  Median:  0.10s
  P95:     0.10s
  P99:     0.10s
  Min:     0.10s
  Max:     0.10s

TTS Generation 4:
  Count:   1
  Mean:    0.07s
  Median:  0.07s
  P95:     0.07s
  P99:     0.07s
  Min:     0.07s
  Max:     0.07s

TTS Generation 5:
  Count:   1
  Mean:    0.08s
  Median:  0.08s
  P95:     0.08s
  P99:     0.08s
  Min:     0.08s
  Max:     0.08s
============================================================

============================================================
ANALYSIS & RECOMMENDATIONS
============================================================

LLM Mean Latency: 1.20s
  ✓ LLM latency is reasonable

TTS Mean Latency: 0.31s
  ✓ TTS latency is good

End-to-End Mean Latency: 0.91s
  (This is the key roundtrip metric)
  ✓ Roundtrip latency is acceptable
============================================================
